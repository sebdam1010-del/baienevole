# Scraping du site Baie des Singes

Ce document explique comment utiliser le systÃ¨me de scraping pour importer automatiquement les Ã©vÃ©nements depuis le site officiel https://www.baiedessinges.com/programme/liste/

## ğŸ¯ FonctionnalitÃ©s

Le script de scraping rÃ©cupÃ¨re automatiquement :
- âœ… **Nom de l'Ã©vÃ©nement**
- âœ… **Date de l'Ã©vÃ©nement**
- âœ… **Description**
- âœ… **Image** (tÃ©lÃ©chargÃ©e et stockÃ©e localement)
- âœ… **Tarif**
- âœ… **URL de la page** sur le site officiel

## ğŸ“‹ Nouveaux champs ajoutÃ©s

Le modÃ¨le `Event` a Ã©tÃ© enrichi avec :

```prisma
model Event {
  // ... champs existants
  imageUrl   String?  // URL locale de l'image (/images/events/...)
  tarif      String?  // Tarif de l'Ã©vÃ©nement
  urlSite    String?  // URL de la page sur le site officiel
}
```

## ğŸš€ Utilisation

### 1. Via la ligne de commande

```bash
# Lancer le scraping manuellement
npm run scrape:events
```

Le script va :
1. Se connecter au site officiel
2. Extraire tous les Ã©vÃ©nements de la page
3. TÃ©lÃ©charger les images dans `public/images/events/`
4. CrÃ©er ou mettre Ã  jour les Ã©vÃ©nements dans la base de donnÃ©es
5. Afficher un rÃ©sumÃ© avec les statistiques

**Sortie exemple :**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Scraping Baie des Singes - Ã‰vÃ©nements    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â„¹ DÃ©marrage du scraping...
âœ“ Dossier images crÃ©Ã©: /var/www/baienevole/public/images/events
â„¹ Navigation vers https://www.baiedessinges.com/programme/liste/...
â„¹ Extraction des Ã©vÃ©nements...
âœ“ 15 Ã©vÃ©nement(s) trouvÃ©(s)
â„¹ Sauvegarde dans la base de donnÃ©es...
â„¹ TÃ©lÃ©chargement image: Concert acoustique
âœ“ CrÃ©Ã©: Concert acoustique
â„¹ TÃ©lÃ©chargement image: Spectacle de marionnettes
âœ“ CrÃ©Ã©: Spectacle de marionnettes

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              RÃ©sumÃ©                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ“ Ã‰vÃ©nements crÃ©Ã©s: 12
â„¹ Ã‰vÃ©nements mis Ã  jour: 3
```

### 2. Via l'API (interface admin)

Les administrateurs peuvent dÃ©clencher le scraping depuis l'interface :

**POST** `/api/admin/scrape/events`
```bash
curl -X POST http://localhost:3000/api/admin/scrape/events \
  -H "Authorization: Bearer YOUR_ADMIN_TOKEN"
```

**RÃ©ponse :**
```json
{
  "success": true,
  "message": "Scraping terminÃ© avec succÃ¨s",
  "stats": {
    "found": 15,
    "created": 12,
    "updated": 3,
    "errors": 0
  }
}
```

**GET** `/api/admin/scrape/status`

Obtenir le statut du dernier scraping :

```bash
curl http://localhost:3000/api/admin/scrape/status \
  -H "Authorization: Bearer YOUR_ADMIN_TOKEN"
```

**RÃ©ponse :**
```json
{
  "success": true,
  "stats": {
    "totalImported": 15,
    "lastImported": {
      "name": "Concert acoustique",
      "date": "2025-01-06T14:25:30.000Z"
    }
  }
}
```

## ğŸ”§ Configuration

### Adapter les sÃ©lecteurs CSS

Le site peut Ã©voluer et les sÃ©lecteurs CSS peuvent changer. Pour adapter le script :

1. Ouvrir `scripts/scrapeEvents.js`
2. Modifier les sÃ©lecteurs dans la fonction `scrapeEvents()` :

```javascript
// Ligne ~105
const eventElements = document.querySelectorAll('.event-item, .programme-item');

// Adapter selon la structure HTML actuelle
const titleEl = el.querySelector('h2, h3, .title');
const imageEl = el.querySelector('img');
const linkEl = el.querySelector('a[href*="/spectacle/"]');
```

### DÃ©boguer le HTML

Si aucun Ã©vÃ©nement n'est trouvÃ©, le script sauvegarde automatiquement le HTML dans `debug-scraping.html` :

```bash
# Lancer le scraping
npm run scrape:events

# Si Ã©chec, inspecter le HTML
cat debug-scraping.html
```

Vous pouvez ensuite identifier les bons sÃ©lecteurs CSS Ã  utiliser.

### ParamÃ¨tres par dÃ©faut

Certains paramÃ¨tres sont configurables dans le script :

```javascript
// Configuration (ligne ~13)
const SITE_URL = 'https://www.baiedessinges.com/programme/liste/';
const IMAGES_DIR = path.join(__dirname, '../public/images/events');
const CURRENT_SEASON = 30; // Saison 2024-2025

// Valeurs par dÃ©faut pour les Ã©vÃ©nements (ligne ~206)
horaireArrivee: '19:00',
horaireDepart: '23:00',
nombreSpectatursAttendus: 100,
nombreBenevolesRequis: 5,
```

## ğŸ“ Structure des fichiers

```
baienevole/
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ scrapeEvents.js         # Script principal de scraping
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â””â”€â”€ scrapeController.js # API endpoints pour le scraping
â”‚   â””â”€â”€ routes/
â”‚       â””â”€â”€ adminRoutes.js      # Routes admin (/api/admin/scrape/*)
â”œâ”€â”€ public/
â”‚   â””â”€â”€ images/
â”‚       â””â”€â”€ events/             # Images tÃ©lÃ©chargÃ©es
â”‚           â”œâ”€â”€ concert-acoustique-1704563130456.jpg
â”‚           â””â”€â”€ spectacle-marionnettes-1704563145789.jpg
â”œâ”€â”€ prisma/
â”‚   â””â”€â”€ schema.prisma           # ModÃ¨le Event avec nouveaux champs
â””â”€â”€ debug-scraping.html         # HTML de dÃ©bogage (si Ã©chec)
```

## ğŸ”„ Automatisation

### Cron job quotidien

Pour importer automatiquement les nouveaux Ã©vÃ©nements :

```bash
# Ã‰diter le crontab
crontab -e

# Ajouter cette ligne pour exÃ©cuter tous les jours Ã  3h00
0 3 * * * cd /var/www/baienevole && npm run scrape:events >> logs/scraping.log 2>&1
```

### Script de dÃ©ploiement

Le script de dÃ©ploiement peut Ã©galement inclure un scraping initial :

```bash
# Dans scripts/deploy.sh
echo "Import des Ã©vÃ©nements depuis le site..."
npm run scrape:events
```

## ğŸ› DÃ©pannage

### Aucun Ã©vÃ©nement trouvÃ©

**Causes possibles :**
- Les sÃ©lecteurs CSS ont changÃ© â†’ Adapter les sÃ©lecteurs
- Le site utilise du JavaScript pour charger le contenu â†’ Puppeteer peut prendre du temps
- Le site a une protection anti-bot â†’ VÃ©rifier les headers User-Agent

**Solution :**
```bash
# Inspecter le HTML tÃ©lÃ©chargÃ©
npm run scrape:events
cat debug-scraping.html
```

### Erreur de tÃ©lÃ©chargement d'image

**Causes :**
- URL d'image invalide
- Timeout rÃ©seau
- Image protÃ©gÃ©e

**Solution :**
Le script continue mÃªme si une image Ã©choue. L'Ã©vÃ©nement sera crÃ©Ã© sans image.

### Erreur Puppeteer

**Causes :**
- Chrome/Chromium non installÃ©
- Permissions insuffisantes

**Solution (Linux):**
```bash
# Installer les dÃ©pendances Chromium
sudo apt-get install -y chromium-browser
sudo apt-get install -y libx11-xcb1 libxcomposite1 libxdamage1 libxrandr2 libgbm1 libgtk-3-0 libnss3 libasound2
```

**Solution (Docker):**
```dockerfile
# Dans le Dockerfile
RUN apt-get update && apt-get install -y \
    chromium \
    fonts-liberation \
    libasound2 \
    libatk-bridge2.0-0 \
    libgbm1 \
    libgtk-3-0 \
    libnspr4 \
    libnss3 \
    libx11-xcb1 \
    libxss1 \
    xdg-utils
```

## ğŸ“Š Gestion des doublons

Le script vÃ©rifie automatiquement les doublons par :
- **Nom de l'Ã©vÃ©nement** (exact)
- **Date** (mÃªme jour)

Si un Ã©vÃ©nement existe dÃ©jÃ  :
- âœ… Il est **mis Ã  jour** avec les nouvelles informations
- âœ… L'image est re-tÃ©lÃ©chargÃ©e
- âœ… Le tarif et l'URL sont mis Ã  jour

## ğŸ”’ SÃ©curitÃ©

### Permissions

Les routes de scraping sont protÃ©gÃ©es :
- âœ… Authentification JWT requise
- âœ… RÃ´le Admin requis
- âœ… AccÃ¨s refusÃ© pour les bÃ©nÃ©voles

### Validation des donnÃ©es

Le script valide :
- âœ… Format des URLs (images et pages)
- âœ… Format des dates
- âœ… Taille des images (timeout 10s)
- âœ… CaractÃ¨res spÃ©ciaux dans les noms de fichiers

### Rate limiting

Pour Ã©viter de surcharger le site :
- Navigation avec `networkidle2` (attend la fin du chargement)
- User-Agent standard
- Pas de parallÃ©lisation agressive

## ğŸ“š Documentation API

La documentation complÃ¨te est disponible sur Swagger UI :

**http://localhost:3000/api-docs**

Sections concernÃ©es :
- **Admin** â†’ `POST /api/admin/scrape/events`
- **Admin** â†’ `GET /api/admin/scrape/status`

## ğŸ¨ Affichage des images dans l'interface

Les images sont servies via le serveur Express :

```javascript
// Dans le composant React
<img
  src={`http://localhost:3000${event.imageUrl}`}
  alt={event.nom}
/>

// Exemple: http://localhost:3000/images/events/concert-acoustique-1704563130456.jpg
```

## ğŸš€ Prochaines Ã©tapes

AmÃ©liorations possibles :
- [ ] Scraper les horaires prÃ©cis depuis la page dÃ©taillÃ©e
- [ ] RÃ©cupÃ©rer le nombre de spectateurs attendus
- [ ] Scraper d'autres sites d'Ã©vÃ©nements culturels
- [ ] Ajouter un systÃ¨me de notification pour les nouveaux Ã©vÃ©nements
- [ ] Interface admin pour configurer les sÃ©lecteurs CSS
- [ ] Historique des scrapings avec logs dÃ©taillÃ©s

## ğŸ’¡ Exemples d'utilisation

### Import initial

```bash
# Premier import depuis le site
npm run scrape:events
```

### Mise Ã  jour mensuelle

```bash
# Mettre Ã  jour les Ã©vÃ©nements existants
npm run scrape:events
# Les Ã©vÃ©nements existants seront mis Ã  jour, les nouveaux crÃ©Ã©s
```

### Test aprÃ¨s modification du site

```bash
# 1. Tester le scraping
npm run scrape:events

# 2. VÃ©rifier les Ã©vÃ©nements importÃ©s
npx prisma studio
# Ouvrir la table Event et vÃ©rifier les champs imageUrl, tarif, urlSite

# 3. Tester l'affichage des images
curl http://localhost:3000/images/events/
```

---

Pour toute question ou problÃ¨me, consultez le [guide de dÃ©pannage](./DEPLOYMENT.md#dÃ©pannage) ou ouvrez une issue sur GitHub.
